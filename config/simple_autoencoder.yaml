batch_size: 256
decoder_activation_1: relu
decoder_batch_norm_1: false
decoder_dropout_1: 0.0
decoder_l2_1: 0.0
decoder_layers: 1
decoder_units_1: 128
encoder_activation_1: relu
encoder_batch_norm_1: false
encoder_dropout_1: 0.0
encoder_l2_1: 0.0
encoder_layers: 1
encoder_units_1: 128
epochs: 5
latent_activation: relu
latent_space_dim: 2
learning_rate: 0.0001
test_size: 0.2
