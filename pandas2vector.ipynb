{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis/autoencoders_census/blob/main/pandas2vector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code that transforms a dataframe to vector format and vice versa\n",
        "\n",
        "Transform and reverse transform the data, allowing for preprocessing and postprocessing steps in pipelines. It provides functionality to handle missing values, encode categorical variables, and scale numeric variables."
      ],
      "metadata": {
        "id": "qXLsxNHalfrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from pandas.api.types import is_numeric_dtype"
      ],
      "metadata": {
        "id": "DwSsRb4Jni6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Table2Vector:\n",
        "    \"\"\"\n",
        "    Class for transforming data for machine learning.\n",
        "\n",
        "    This class handles transformations like one-hot encoding for categorical data,\n",
        "    min-max scaling for numerical data, and handling missing data.\n",
        "\n",
        "    This class does not handle textual data or datetime variabls.\n",
        "    \"\"\"\n",
        "\n",
        "    # Ignore for now. We will use it later\n",
        "    VAR_TYPES = [\n",
        "        'categorical',\n",
        "        'numeric',\n",
        "        'datetime',\n",
        "        'text',\n",
        "        'binary',\n",
        "        'missing_indicator' # indicator variable for missing values in another column\n",
        "    ]\n",
        "\n",
        "    def __init__(self, variable_types):\n",
        "        \"\"\"Initialize the transformer with the variable types dictionary.\"\"\"\n",
        "        self.SEP = '__'\n",
        "        self.MISSING = 'MISSING__'\n",
        "\n",
        "        self.var_types = {\n",
        "            'categorical': [],\n",
        "            'numeric': [],\n",
        "            'datetime': [],\n",
        "            'text': [],\n",
        "            'binary': [],\n",
        "            'missing_indicator': []\n",
        "        }\n",
        "\n",
        "        for k in  self.var_types:\n",
        "            self.var_types[k] = [var for var,var_type in variable_types.items() if var_type == k]\n",
        "\n",
        "        self.one_hot_encoders = {}\n",
        "        self.min_max_scalers = {}\n",
        "\n",
        "    def vectorize_table(self, original_df, add_missing_indicators=False):\n",
        "        \"\"\"\n",
        "        Transform the dataframe according to the variable types.\n",
        "\n",
        "        Categorical variables are one-hot encoded, numeric variables are min-max scaled,\n",
        "        and missing values are replaced with dummy variables.\n",
        "\n",
        "        Returns:\n",
        "        - The transformed dataframe.\n",
        "        - Dictionaries with fitted OneHotEncoders and MinMaxScalers for each column.\n",
        "        \"\"\"\n",
        "        vectorized_df = original_df.copy()\n",
        "\n",
        "\n",
        "\n",
        "        for column in vectorized_df.columns:\n",
        "            # We use a MixMaxScaler for numeric variables\n",
        "            if column in self.var_types['numeric'] and is_numeric_dtype(vectorized_df[column]):\n",
        "                min_max_scaler = MinMaxScaler()\n",
        "                non_na_rows = vectorized_df[column].notna()\n",
        "                vectorized_df.loc[non_na_rows, column] = min_max_scaler.fit_transform(vectorized_df.loc[non_na_rows, [column]]).ravel()\n",
        "                self.min_max_scalers[column] = min_max_scaler\n",
        "            elif column in self.var_types['categorical']:\n",
        "                one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore', drop=(np.nan,))\n",
        "                df_encoded = pd.DataFrame(one_hot_encoder.fit_transform(vectorized_df[[column]]))\n",
        "                df_encoded.columns = [f\"{column}{self.SEP}{cat}\" for cat in one_hot_encoder.categories_[0] if str(cat) != 'nan']\n",
        "                vectorized_df = pd.concat([vectorized_df, df_encoded], axis=1)\n",
        "                vectorized_df = vectorized_df.drop(column, axis=1)\n",
        "                self.one_hot_encoders[column] = one_hot_encoder\n",
        "\n",
        "        # Add missing indicators\n",
        "        if add_missing_indicators:\n",
        "          missing_indicators = self.add_missing_indicators(original_df)\n",
        "          vectorized_df = pd.concat([vectorized_df, missing_indicators], axis='columns')\n",
        "\n",
        "        return vectorized_df\n",
        "\n",
        "\n",
        "    def add_missing_indicators(self, df):\n",
        "        \"\"\"\n",
        "        Adds binary columns to the dataframe indicating the presence of missing values.\n",
        "\n",
        "        For each column in the dataframe, this function adds a corresponding column\n",
        "        with a binary indicator of whether the value in that row is missing (NaN).\n",
        "        These new columns are named 'missing_<column_name>' and are appended to the dataframe.\n",
        "\n",
        "        Args:\n",
        "            df (pd.DataFrame): The input pandas DataFrame.\n",
        "\n",
        "        Returns:\n",
        "            result (pd.DataFrame): The DataFrame with added missing value indicator columns.\n",
        "        \"\"\"\n",
        "\n",
        "        # Create DataFrame with indicator of missing values\n",
        "\n",
        "        # We will create missing value indicators if\n",
        "        # (a) there is no such missing value indicator already for the column and\n",
        "        # (b) the column is not already a missing value indicator\n",
        "        cols = [c for c in df.columns if not c.startswith(self.MISSING) and f'{self.MISSING}{c}' not in df.columns]\n",
        "        df_missing = pd.concat([df[c].isnull().astype(int) for c in cols], axis=1)\n",
        "        df_missing.columns = [f'{self.MISSING}{c}' for c in cols]\n",
        "\n",
        "\n",
        "\n",
        "        return df_missing\n",
        "\n",
        "    @staticmethod\n",
        "    def proba_to_onehot(proba):\n",
        "        \"\"\"Convert a vector of probabilities into a max-likelihood one-hot vector.\"\"\"\n",
        "        onehot = np.zeros_like(proba)\n",
        "        onehot[np.arange(len(proba)), np.argmax(proba, axis=1)] = 1\n",
        "        return onehot\n",
        "\n",
        "\n",
        "    def tabularize_vector(self, vectorized_df, restore_missing_values=False):\n",
        "        \"\"\"\n",
        "        Reverse the transformations applied to the dataframe.\n",
        "\n",
        "        One-hot encoded categorical variables are decoded and min-max scaled numeric variables\n",
        "        are inverse scaled.\n",
        "\n",
        "        Returns the original dataframe.\n",
        "        \"\"\"\n",
        "        df = vectorized_df.copy()\n",
        "\n",
        "\n",
        "        for column in self.var_types['categorical']:\n",
        "            one_hot_encoder = self.one_hot_encoders[column]\n",
        "            original_cols = [col for col in df.columns if col.startswith(f\"{column}{self.SEP}\")]\n",
        "            onehot_encoded = df[original_cols].values\n",
        "            # Identify rows where all one-hot columns are zero\n",
        "            all_zero_rows = (onehot_encoded == 0).all(axis=1)\n",
        "\n",
        "            # Convert probabilities to one-hot encoding and perform inverse transformation\n",
        "            onehot = self.proba_to_onehot(onehot_encoded)\n",
        "            df_original = pd.DataFrame(one_hot_encoder.inverse_transform(onehot), columns=[column])\n",
        "\n",
        "            # Set original value to NaN for rows that were all zeros in the one-hot encoded data\n",
        "            df_original.loc[all_zero_rows, column] = np.nan\n",
        "\n",
        "            df = pd.concat([df.drop(original_cols, axis=1), df_original], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for column in self.var_types['numeric']:\n",
        "            min_max_scaler = self.min_max_scalers[column]\n",
        "            non_na_rows = df[column].notna()\n",
        "            inverse_transformed = min_max_scaler.inverse_transform(df.loc[non_na_rows, [column]])\n",
        "            df.loc[non_na_rows, column] = inverse_transformed.flatten()\n",
        "\n",
        "        # Remove missing indicators\n",
        "        df = df.drop([col for col in df.columns if col.startswith(self.MISSING)], axis=1)\n",
        "\n",
        "        if restore_missing_values:\n",
        "            # TODO: Need to also set to NULL the corresponding values in the corresponding columns\n",
        "            pass\n",
        "\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "s1Myubs5o9Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "class TestDataTransformer(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.variable_types = {\n",
        "            'age': 'numeric',\n",
        "            'gender': 'categorical',\n",
        "            'income': 'numeric',\n",
        "            'gender_at_birth': 'categorical',\n",
        "\n",
        "        }\n",
        "        self.vectorizer = Table2Vector(self.variable_types)\n",
        "        self.SEP = self.vectorizer.SEP\n",
        "        self.MISSING = self.vectorizer.MISSING\n",
        "\n",
        "        self.data = pd.DataFrame({\n",
        "            'age': [25, 30, 35, np.nan],\n",
        "            'gender': ['male', 'female', np.nan, 'female'],\n",
        "            'income': [50000.0, np.nan, 70000.0, 80000.0],\n",
        "            'gender_at_birth': ['female', 'female', np.nan, 'male'],\n",
        "        })\n",
        "\n",
        "    def test_add_missing_indicators(self):\n",
        "\n",
        "        df = self.data.copy()\n",
        "        vectorized = self.vectorizer.vectorize_table(df, add_missing_indicators=True)\n",
        "\n",
        "        # Check that the output DataFrame has the correct number of columns\n",
        "        expected_columns = ['age', 'income',\n",
        "                            'gender__female', 'gender__male',\n",
        "\n",
        "                            'gender_at_birth__female', 'gender_at_birth__male',\n",
        "                            self.MISSING+'age',\n",
        "                            self.MISSING+'gender', self.MISSING+'income',\n",
        "                            self.MISSING+'gender_at_birth']\n",
        "        print(vectorized.columns)\n",
        "        self.assertListEqual(list(vectorized.columns), expected_columns)\n",
        "\n",
        "        # Check that the added columns in the output DataFrame start with 'missing_'\n",
        "        missing_cols = [col for col in vectorized.columns if col.startswith(self.MISSING)]\n",
        "        self.assertEqual(len(missing_cols), 4)\n",
        "\n",
        "        # Check that 'missing_' columns contain only 0s and 1s\n",
        "        for col in missing_cols:\n",
        "            self.assertTrue(set(vectorized[col].unique()).issubset({0, 1}))\n",
        "\n",
        "        # Check that the number of 1s in 'missing_' columns matches the number of NaN values in the original DataFrame\n",
        "        for original_col in self.data.columns:\n",
        "                missing_col = self.MISSING+original_col\n",
        "                self.assertEqual(vectorized[missing_col].sum(), self.data[original_col].isnull().sum())\n",
        "\n",
        "\n",
        "    def test_transform_dataframe(self):\n",
        "\n",
        "        vectorized_df = self.vectorizer.vectorize_table(self.data, add_missing_indicators=True)\n",
        "\n",
        "        # Check that original DataFrame has been transformed properly\n",
        "        self.assertNotIn('gender', vectorized_df.columns)\n",
        "        self.assertIn('gender__male', vectorized_df.columns)\n",
        "        self.assertIn('gender__female', vectorized_df.columns)\n",
        "\n",
        "        # Check that missing values have been handled correctly\n",
        "        self.assertEqual(vectorized_df.loc[3, 'MISSING__age'], 1)\n",
        "        self.assertEqual(vectorized_df.loc[0, 'MISSING__age'], 0)\n",
        "\n",
        "        # Check that numeric columns have been scaled correctly\n",
        "        self.assertEqual(vectorized_df.loc[0, 'age'], 0)\n",
        "        self.assertEqual(vectorized_df.loc[1, 'age'], 0.5)\n",
        "        self.assertEqual(vectorized_df.loc[2, 'age'], 1)\n",
        "        self.assertTrue(np.isnan(vectorized_df.loc[3, 'age']))\n",
        "\n",
        "\n",
        "    def test_proba_to_onehot(self):\n",
        "        proba = np.array([[0.1, 0.9], [0.7, 0.3]])\n",
        "        expected_onehot = np.array([[0, 1], [1, 0]])\n",
        "\n",
        "        np.testing.assert_array_equal(self.vectorizer.proba_to_onehot(proba), expected_onehot)\n",
        "\n",
        "    def test_reverse_transform_dataframe(self):\n",
        "        vector_df = self.vectorizer.vectorize_table(self.data)\n",
        "        reversed_df = self.vectorizer.tabularize_vector(vector_df)\n",
        "\n",
        "        # Check that DataFrame has been reversed correctly\n",
        "        pd.testing.assert_frame_equal(reversed_df, self.data, check_like=True)\n",
        "\n",
        "        # Check that the missing data has been reversed correctly\n",
        "        self.assertTrue(pd.isnull(reversed_df.loc[3, 'age']))\n",
        "\n",
        "        # Check that the numeric scaling has been reversed correctly\n",
        "        self.assertTrue('age' in reversed_df.columns)\n",
        "        self.assertTrue('income' in reversed_df.columns)\n",
        "        self.assertListEqual(list(self.data['age'].dropna()), list(reversed_df['age'].dropna()))\n",
        "        self.assertTrue(np.array_equal(np.isnan(self.data['income']), np.isnan(reversed_df['income'])))\n",
        "\n",
        "        # Check that the categorical encoding has been reversed correctly\n",
        "        self.assertTrue('gender' in reversed_df.columns)\n",
        "        self.assertListEqual(list(self.data['gender']), list(reversed_df['gender']))\n",
        "\n",
        "def run_tests(test_class):\n",
        "    suite = unittest.TestLoader().loadTestsFromTestCase(test_class)\n",
        "    runner = unittest.TextTestRunner()\n",
        "    runner.run(suite)\n"
      ],
      "metadata": {
        "id": "PXzlb49JnaLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  run_tests(TestDataTransformer)"
      ],
      "metadata": {
        "id": "Fa1q7NuXV0GS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}