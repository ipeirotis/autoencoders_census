{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMBbKikGT2qc8x4T8w5DAwG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis/autoencoders_census/blob/main/pandas2vector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRjzYpzulPNo"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ipeirotis/autoencoders_census.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd autoencoders_census"
      ],
      "metadata": {
        "id": "XFbxD_XNlRw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code that transforms a dataframe to vector format and vice versa\n",
        "\n",
        "Transform and reverse transform the data, allowing for preprocessing and postprocessing steps in pipelines. It provides functionality to handle missing values, encode categorical variables, and scale numeric variables."
      ],
      "metadata": {
        "id": "qXLsxNHalfrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from pandas.api.types import is_numeric_dtype"
      ],
      "metadata": {
        "id": "DwSsRb4Jni6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IirSHZFMleyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class DataTransformer:\n",
        "    \"\"\"\n",
        "    Class for transforming data for machine learning.\n",
        "\n",
        "    This class handles transformations like one-hot encoding for categorical data,\n",
        "    min-max scaling for numerical data, and handling missing data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, variable_types):\n",
        "        \"\"\"Initialize the transformer with the variable types dictionary.\"\"\"\n",
        "        self.variable_types = variable_types\n",
        "        self.one_hot_encoders = {}\n",
        "        self.min_max_scalers = {}\n",
        "\n",
        "    def transform_dataframe(self, df):\n",
        "        \"\"\"\n",
        "        Transform the dataframe according to the variable types.\n",
        "\n",
        "        Categorical variables are one-hot encoded, numeric variables are min-max scaled,\n",
        "        and missing values are replaced with dummy variables.\n",
        "\n",
        "        Returns:\n",
        "        - The transformed dataframe.\n",
        "        - Dictionaries with fitted OneHotEncoders and MinMaxScalers for each column.\n",
        "        \"\"\"\n",
        "        # Add dummies for missing values\n",
        "        df_missing = pd.concat([df[c].isnull().astype(int) for c in df.columns], axis = 1)\n",
        "        df_missing.columns = [f'missing_{c}' for c in df.columns]\n",
        "        df = pd.concat([df, df_missing], axis='columns')\n",
        "\n",
        "        for column, variable_type in self.variable_types.items():\n",
        "            if variable_type == 'categorical':\n",
        "                one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "                df_encoded = pd.DataFrame(one_hot_encoder.fit_transform(df[[column]]))\n",
        "                df_encoded.columns = [f\"{column}_{cat}\" for cat in one_hot_encoder.categories_[0]]\n",
        "                df = pd.concat([df, df_encoded], axis=1)\n",
        "                df = df.drop(column, axis=1)\n",
        "                self.one_hot_encoders[column] = one_hot_encoder\n",
        "            elif variable_type == 'numeric' and is_numeric_dtype(df[column]):\n",
        "                min_max_scaler = MinMaxScaler()\n",
        "                df[column] = min_max_scaler.fit_transform(df[[column]])\n",
        "                self.min_max_scalers[column] = min_max_scaler\n",
        "\n",
        "        return df\n",
        "\n",
        "    @staticmethod\n",
        "    def proba_to_onehot(proba):\n",
        "        \"\"\"Convert a vector of probabilities into a max-likelihood one-hot vector.\"\"\"\n",
        "        onehot = np.zeros_like(proba)\n",
        "        onehot[np.arange(len(proba)), np.argmax(proba, axis=1)] = 1\n",
        "        return onehot\n",
        "\n",
        "    def reverse_transform_dataframe(self, df):\n",
        "        \"\"\"\n",
        "        Reverse the transformations applied to the dataframe.\n",
        "\n",
        "        One-hot encoded categorical variables are decoded and min-max scaled numeric variables\n",
        "        are inverse scaled.\n",
        "\n",
        "        Returns the original dataframe.\n",
        "        \"\"\"\n",
        "        for column, variable_type in self.variable_types.items():\n",
        "            if variable_type == 'categorical':\n",
        "                one_hot_encoder = self.one_hot_encoders[column]\n",
        "                original_cols = [col for col in df.columns if col.startswith(f\"{column}_\")]\n",
        "                df_proba = df[original_cols].values\n",
        "                onehot = self.proba_to_onehot(df_proba)\n",
        "                df_original = pd.DataFrame(one_hot_encoder.inverse_transform(onehot))\n",
        "                df_original.columns = [column]\n",
        "                df = pd.concat([df.drop(original_cols, axis=1), df_original], axis=1)\n",
        "            elif variable_type == 'numeric' and is_numeric_dtype(df[column]):\n",
        "                min_max_scaler = self.min_max_scalers[column]\n",
        "                df[column] = min_max_scaler.inverse_transform(df[[column]])\n",
        "\n",
        "        # Removing the created missing value columns\n",
        "        missing_cols = [col for col in df.columns if col.startswith('missing_')]\n",
        "        df = df.drop(columns=missing_cols)\n",
        "\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "s1Myubs5o9Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "class TestDataTransformer(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.variable_types = {\n",
        "            'age': 'numeric',\n",
        "            'gender': 'categorical',\n",
        "            'income': 'numeric'\n",
        "        }\n",
        "        self.transformer = DataTransformer(self.variable_types)\n",
        "        self.data = pd.DataFrame({\n",
        "            'age': [25, 30, 35, np.nan],\n",
        "            'gender': ['male', 'female', 'male', 'female'],\n",
        "            'income': [50000, 60000, 70000, 80000]\n",
        "        })\n",
        "\n",
        "    def test_transform_dataframe(self):\n",
        "        transformed_df = self.transformer.transform_dataframe(self.data)\n",
        "\n",
        "        # Check that original DataFrame has been transformed properly\n",
        "        self.assertNotIn('gender', transformed_df.columns)\n",
        "        self.assertIn('gender_male', transformed_df.columns)\n",
        "        self.assertIn('gender_female', transformed_df.columns)\n",
        "\n",
        "        # Check that missing values have been handled correctly\n",
        "        self.assertEqual(transformed_df.loc[3, 'missing_age'], 1)\n",
        "        self.assertEqual(transformed_df.loc[0, 'missing_age'], 0)\n",
        "\n",
        "        # Check that numeric columns have been scaled correctly\n",
        "        self.assertEqual(transformed_df.loc[0, 'age'], 0)\n",
        "        self.assertEqual(transformed_df.loc[1, 'age'], 0.5)\n",
        "        self.assertEqual(transformed_df.loc[2, 'age'], 1)\n",
        "        self.assertTrue(np.isnan(transformed_df.loc[3, 'age']))\n",
        "\n",
        "    def test_proba_to_onehot(self):\n",
        "        proba = np.array([[0.1, 0.9], [0.7, 0.3]])\n",
        "        expected_onehot = np.array([[0, 1], [1, 0]])\n",
        "\n",
        "        np.testing.assert_array_equal(self.transformer.proba_to_onehot(proba), expected_onehot)\n",
        "\n",
        "    def test_reverse_transform_dataframe(self):\n",
        "        transformed_df = self.transformer.transform_dataframe(self.data)\n",
        "        reversed_df = self.transformer.reverse_transform_dataframe(transformed_df)\n",
        "\n",
        "        # Check that DataFrame has been reversed correctly\n",
        "        pd.testing.assert_frame_equal(reversed_df, self.data, check_like=True)\n",
        "\n",
        "def run_tests(test_class):\n",
        "    suite = unittest.TestLoader().loadTestsFromTestCase(test_class)\n",
        "    unittest.TextTestRunner().run(suite)\n",
        "\n",
        "run_tests(TestDataTransformer)"
      ],
      "metadata": {
        "id": "PXzlb49JnaLq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}