{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOpyDEUAHSEA6Ao2475J8uJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ipeirotis/autoencoders_census/blob/main/autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgC-DNoNxTC1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Dense, BatchNormalization\n",
        "from keras.models import Model\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "class AutoencoderModel:\n",
        "    def __init__(self):\n",
        "        self.INPUT_SHAPE = None\n",
        "        self.D = 2\n",
        "        self.TEST_SIZE = 0.2\n",
        "        self.RANDOM_STATE = 42\n",
        "        self.SEED = 42\n",
        "        self.MAX_TRIALS = 20\n",
        "        self.EXECUTIONS_PER_TRIAL = 1\n",
        "        self.EPOCHS = 5\n",
        "        self.NUM_TRIALS = 1\n",
        "\n",
        "    def split_train_test(self, df):\n",
        "        # df = df.fillna(0.0)\n",
        "        X_train, X_test = train_test_split(df.copy(), test_size=self.TEST_SIZE, random_state=self.RANDOM_STATE)\n",
        "        # X_train = X_train.values.astype('float32')\n",
        "        # X_test = X_test.values.astype('float32')\n",
        "        # X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:])))\n",
        "        # X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
        "        self.INPUT_SHAPE = X_train.shape[1:]\n",
        "        return X_train.dropna(), X_test.dropna()\n",
        "\n",
        "    @staticmethod\n",
        "    def masked_mse(y_true, y_pred):\n",
        "        mask = tf.math.is_finite(y_true)\n",
        "        y_t = tf.where(tf.math.is_finite(y_true), y_true, 0.0)\n",
        "        y_p = tf.where(tf.math.is_finite(y_pred), y_pred, 0.0)\n",
        "        mse = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "        return tf.reduce_mean(mse(y_t*tf.cast(mask, y_t.dtype), y_p*tf.cast(mask, y_p.dtype)))\n",
        "\n",
        "\n",
        "\n",
        "    def build_encoder(self, hp):\n",
        "        inputs = Input(shape=self.INPUT_SHAPE)\n",
        "        x = Dense(units=hp.Int('encoder_units_1', min_value=16, max_value=256, step=16), activation='relu')(inputs)\n",
        "        x = BatchNormalization()(x)\n",
        "        # x = Dense(units=hp.Int('encoder_units_2', min_value=16, max_value=128, step=16), activation='relu')(x)\n",
        "        # x = BatchNormalization()(x)\n",
        "        latent_space = Dense(units=self.D, activation='relu')(x)\n",
        "        return Model(inputs, latent_space)\n",
        "\n",
        "    def build_decoder(self, hp):\n",
        "        decoder_inputs = Input(shape=(self.D,))\n",
        "        x = Dense(units=hp.Int('decoder_units_1', min_value=16, max_value=256, step=16), activation='relu')(decoder_inputs)\n",
        "        x = BatchNormalization()(x)\n",
        "        # x = Dense(units=hp.Int('decoder_units_2', min_value=32, max_value=256, step=32), activation='relu')(x)\n",
        "        # x = BatchNormalization()(x)\n",
        "        outputs = Dense(units=self.INPUT_SHAPE[0], activation='linear')(x)\n",
        "        return Model(decoder_inputs, outputs)\n",
        "\n",
        "    def build_autoencoder(self, hp):\n",
        "        learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5])\n",
        "        batch_size = hp.Int('batch_size', min_value=16, max_value=256, step=16)\n",
        "        autoencoder_input = Input(shape=self.INPUT_SHAPE)\n",
        "        encoder_output = self.build_encoder(hp)(autoencoder_input)\n",
        "        decoder_output = self.build_decoder(hp)(encoder_output)\n",
        "        autoencoder = Model(autoencoder_input, decoder_output)\n",
        "        autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss='mse')\n",
        "        # autoencoder.summary()\n",
        "        # autoencoder.save(f'{self.DIRECTORY}/autoencoder_model.h5\n",
        "        return autoencoder\n",
        "\n",
        "    def define_tuner(self):\n",
        "        tuner = RandomSearch(\n",
        "            self.build_autoencoder,\n",
        "            objective='val_loss',\n",
        "            max_trials=self.MAX_TRIALS,\n",
        "            executions_per_trial=self.EXECUTIONS_PER_TRIAL,\n",
        "            # directory=self.DIRECTORY,\n",
        "            # project_name=self.PROJECT_NAME,\n",
        "            # overwrite=self.OVERWRITE,\n",
        "            seed=self.SEED\n",
        "            )\n",
        "        return tuner\n"
      ]
    }
  ]
}